name: üç∑ Train Wine Classifier

on:
  workflow_dispatch:
    inputs:
      script_path:
        description: 'Training script to run'
        required: true
        default: 'src/training/train.py'
        type: string
      extra_args:
        description: 'Additional arguments (e.g., --epochs 50 --batch-size 32)'
        required: false
        type: string
      num_cpus:
        description: 'Number of CPUs'
        required: false
        default: '1'
        type: string
      memory:
        description: 'Memory (e.g., 2Gi)'
        required: false
        default: '2Gi'
        type: string
      experiment_name:
        description: 'MLflow experiment name'
        required: false
        default: wine-quality

jobs:
  train:
    name: üèÉ Run Training
    runs-on: self-hosted-local  # Change to ubuntu-latest for production
    steps:
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          mkdir -p ~/.local/bin
          mv kubectl ~/.local/bin/
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > ~/.kube/config
          ~/.local/bin/kubectl cluster-info

      - name: Submit Ray Job
        id: submit
        run: |
          JOB_NAME=${{ github.event.repository.name }}-${{ github.run_id }}
          
          cat <<EOF | ~/.local/bin/kubectl apply -f -
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            name: ${JOB_NAME}
            namespace: ai
            labels:
              repo: ${{ github.event.repository.name }}
              run-id: "${{ github.run_id }}"
          spec:
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.48.0"
              headGroupSpec:
                serviceType: ClusterIP
                template:
                  spec:
                    containers:
                    - name: ray-head
                      image: opencloudhuborg/wine-classifier-training:latest
                      resources:
                        requests:
                          cpu: "${{ inputs.num_cpus }}"
                          memory: "${{ inputs.memory }}"
                      env:
                      - name: MLFLOW_TRACKING_URI
                        value: http://mlflow.mlops.svc.cluster.local:5000
                      - name: MLFLOW_EXPERIMENT_NAME
                        value: ${{ inputs.experiment_name }}
              workerGroupSpecs:
              - replicas: 1
                groupName: worker
                template:
                  spec:
                    containers:
                    - name: ray-worker
                      image: opencloudhuborg/wine-classifier-training:latest
                      resources:
                        requests:
                          cpu: "${{ inputs.num_cpus }}"
                          memory: "${{ inputs.memory }}"
            entrypoint: python ${{ inputs.script_path }} ${{ inputs.extra_args }}
          EOF
          
          echo "job_name=${JOB_NAME}" >> $GITHUB_OUTPUT

      - name: üìä Provide Developer Monitoring Commands
        run: |
          JOB_NAME=${{ steps.submit.outputs.job_name }}
          
          echo "========================================="
          echo "üöÄ RAY JOB SUBMITTED: ${JOB_NAME}"
          echo "üéØ Repository: ${{ github.event.repository.name }}"
          echo "üî¢ Run ID: ${{ github.run_id }}"
          echo "========================================="
          echo ""
          echo "üìã COMMANDS FOR DATA SCIENTISTS & DEVELOPERS:"
          echo ""
          echo "üîç 1Ô∏è‚É£ CHECK JOB STATUS:"
          echo "   kubectl get rayjob -n ai ${JOB_NAME}"
          echo "   kubectl get rayjob -n ai ${JOB_NAME} -o jsonpath='{.status.jobStatus}'"
          echo "   kubectl get rayjob -n ai ${JOB_NAME} -o jsonpath='{.status.jobDeploymentStatus}'"
          echo ""
          echo "üìä 2Ô∏è‚É£ MONITOR CLUSTER RESOURCES:"
          echo "   kubectl get raycluster -n ai"
          echo "   kubectl get pods -n ai -l ray.io/cluster=${JOB_NAME}"
          echo "   kubectl top pods -n ai -l ray.io/cluster=${JOB_NAME}"
          echo ""
          echo "üìù 3Ô∏è‚É£ VIEW LOGS (choose one):"
          echo "   # Real-time logs (all containers):"
          echo "   kubectl logs -n ai -l job-name=${JOB_NAME} -f"
          echo ""
          echo "   # Specific container logs:"
          echo "   kubectl logs -n ai -l ray.io/node-type=head -c ray-head -f"
          echo "   kubectl logs -n ai -l ray.io/node-type=worker -c ray-worker -f"
          echo ""
          echo "   # Job submitter logs:"
          echo "   kubectl logs -n ai job/${JOB_NAME} -f"
          echo ""
          echo "   # Last 100 lines (for completed jobs):"
          echo "   kubectl logs -n ai -l job-name=${JOB_NAME} --tail=100"
          echo ""
          echo "üåê 4Ô∏è‚É£ ACCESS RAY DASHBOARD:"
          echo "   kubectl port-forward -n ai svc/${JOB_NAME}-head-svc 8265:8265"
          echo "   Then open: http://localhost:8265"
          echo "   (Dashboard shows: cluster status, task progress, resource usage)"
          echo ""
          echo "üî¨ 5Ô∏è‚É£ ACCESS MLFLOW UI:"
          echo "   kubectl port-forward -n mlops svc/mlflow 5000:5000"
          echo "   Then open: http://localhost:5000"
          echo "   Experiment: ${{ inputs.experiment_name || 'wine-quality' }}"
          echo ""
          echo "üêõ 6Ô∏è‚É£ DEBUG FAILED JOBS:"
          echo "   # Detailed job description:"
          echo "   kubectl describe rayjob -n ai ${JOB_NAME}"
          echo ""
          echo "   # Pod events and issues:"
          echo "   kubectl describe pods -n ai -l ray.io/cluster=${JOB_NAME}"
          echo ""
          echo "   # Resource constraints:"
          echo "   kubectl get events -n ai --field-selector involvedObject.name=${JOB_NAME}"
          echo ""
          echo "   # Image pull issues:"
          echo "   kubectl get pods -n ai -l ray.io/cluster=${JOB_NAME} -o jsonpath='{.items[*].status.containerStatuses[*].state}'"
          echo ""
          echo "üìà 7Ô∏è‚É£ PERFORMANCE MONITORING:"
          echo "   # Resource usage:"
          echo "   kubectl top pods -n ai -l ray.io/cluster=${JOB_NAME}"
          echo ""
          echo "   # Cluster scaling:"
          echo "   kubectl get raycluster -n ai -o jsonpath='{.items[*].status}'"
          echo ""
          echo "üßπ 8Ô∏è‚É£ CLEANUP (after job completion):"
          echo "   kubectl delete rayjob -n ai ${JOB_NAME}"
          echo "   # Note: RayCluster auto-deletes due to shutdownAfterJobFinishes: true"
          echo ""
          echo "üîÑ 9Ô∏è‚É£ CONTINUOUS MONITORING SCRIPT:"
          echo "   # Save this as monitor-job.sh:"
          echo "   cat > monitor-job.sh << 'SCRIPT'"
          echo "   #!/bin/bash"
          echo "   JOB_NAME=${JOB_NAME}"
          echo "   while true; do"
          echo "     STATUS=\$(kubectl get rayjob -n ai \${JOB_NAME} -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo 'NOT_FOUND')"
          echo "     echo \"\$(date): Job Status: \$STATUS\""
          echo "     [[ \"\$STATUS\" == \"SUCCEEDED\" ]] && echo \"‚úÖ Job completed!\" && break"
          echo "     [[ \"\$STATUS\" == \"FAILED\" ]] && echo \"‚ùå Job failed!\" && break"
          echo "     [[ \"\$STATUS\" == \"NOT_FOUND\" ]] && echo \"üîç Job not found, may be deleted\" && break"
          echo "     sleep 10"
          echo "   done"
          echo "   SCRIPT"
          echo "   chmod +x monitor-job.sh && ./monitor-job.sh"
          echo ""
          echo "========================================="
          echo "üí° TIP: Use 'kubectl get pods -n ai -w' to watch pod changes in real-time"
          echo "üí° TIP: Check MLflow at http://localhost:5000 for experiment results"
          echo "========================================="