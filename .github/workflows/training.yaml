name: üç∑ Train Wine Classifier

on:
  workflow_dispatch:
    inputs:
      script_path:
        description: 'Training script to run'
        required: true
        default: 'src/training/train.py'
        type: string
      extra_args:
        description: 'Additional arguments (e.g., --epochs 50 --batch-size 32)'
        required: false
        type: string
      num_cpus:
        description: 'Number of CPUs'
        required: false
        default: '1'
        type: string
      memory:
        description: 'Memory (e.g., 2Gi)'
        required: false
        default: '2Gi'
        type: string
      experiment_name:
        description: 'MLflow experiment name'
        required: false
        default: wine-quality

jobs:
  train:
    name: üèÉ Run Training
    runs-on: self-hosted-local  # Change to ubuntu-latest for production
    steps:
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          mkdir -p ~/.local/bin
          mv kubectl ~/.local/bin/
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > ~/.kube/config
          ~/.local/bin/kubectl cluster-info

      - name: Submit Ray Job
        id: submit
        run: |
          JOB_NAME=${{ github.event.repository.name }}-${{ github.run_id }}
          
          cat <<EOF | ~/.local/bin/kubectl apply -f -
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            name: ${JOB_NAME}
            namespace: ai
            labels:
              repo: ${{ github.event.repository.name }}
              run-id: "${{ github.run_id }}"
          spec:
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.48.0"
              headGroupSpec:
                serviceType: ClusterIP
                template:
                  spec:
                    containers:
                    - name: ray-head
                      image: opencloudhuborg/wine-classifier-training:latest
                      resources:
                        requests:
                          cpu: "${{ inputs.num_cpus }}"
                          memory: "${{ inputs.memory }}"
                      env:
                      - name: MLFLOW_TRACKING_URI
                        value: http://mlflow.mlops.svc.cluster.local:5000
                      - name: MLFLOW_EXPERIMENT_NAME
                        value: ${{ inputs.experiment_name }}
              workerGroupSpecs:
              - replicas: 1
                groupName: worker
                template:
                  spec:
                    containers:
                    - name: ray-worker
                      image: opencloudhuborg/wine-classifier-training:latest
                      resources:
                        requests:
                          cpu: "${{ inputs.num_cpus }}"
                          memory: "${{ inputs.memory }}"
            entrypoint: python ${{ inputs.script_path }} ${{ inputs.extra_args }}
          EOF
          
          echo "job_name=${JOB_NAME}" >> $GITHUB_OUTPUT

      - name: üìä Provide Debug Commands
        run: |
          JOB_NAME=${{ steps.submit.outputs.job_name }}
          
          echo "========================================="
          echo "üöÄ RAY JOB SUBMITTED: ${JOB_NAME}"
          echo "========================================="
          echo ""
          echo "üìã COMMANDS FOR DATA SCIENTISTS:"
          echo ""
          echo "1Ô∏è‚É£ Check job status:"
          echo "   kubectl get rayjob -n ai ${JOB_NAME}"
          echo ""
          echo "2Ô∏è‚É£ Watch job logs (real-time):"
          echo "   kubectl logs -n ai -l job-name=${JOB_NAME} -f"
          echo ""
          echo "3Ô∏è‚É£ Access Ray Dashboard (while job runs):"
          echo "   kubectl port-forward -n ai svc/${JOB_NAME}-head-svc 8265:8265"
          echo "   Then open: http://localhost:8265"
          echo ""
          echo "4Ô∏è‚É£ Get Python script output:"
          echo "   kubectl logs -n ai \$(kubectl get pods -n ai -l job-name=${JOB_NAME} -o jsonpath='{.items[0].metadata.name}')"
          echo ""
          echo "5Ô∏è‚É£ Debug if job fails:"
          echo "   kubectl describe rayjob -n ai ${JOB_NAME}"
          echo "   kubectl describe pods -n ai -l ray.io/cluster=${JOB_NAME}"
          echo ""
          echo "========================================="

      - name: üîç Monitor Job Status
        run: |
          JOB_NAME=${{ steps.submit.outputs.job_name }}
          
          echo "Monitoring job execution..."
          for i in {1..60}; do
            STATUS=$(~/.local/bin/kubectl get rayjob -n ai ${JOB_NAME} -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "PENDING")
            DEPLOYMENT_STATUS=$(~/.local/bin/kubectl get rayjob -n ai ${JOB_NAME} -o jsonpath='{.status.jobDeploymentStatus}' 2>/dev/null || echo "Initializing")
            
            echo "[$i/60] Job Status: $STATUS | Deployment: $DEPLOYMENT_STATUS"
            
            if [[ "$STATUS" == "SUCCEEDED" ]]; then
              echo "‚úÖ Job completed successfully!"
              break
            elif [[ "$STATUS" == "FAILED" ]]; then
              echo "‚ùå Job failed! Getting logs..."
              ~/.local/bin/kubectl logs -n ai -l job-name=${JOB_NAME} --tail=100
              ~/.local/bin/kubectl describe rayjob -n ai ${JOB_NAME}
              exit 1
            fi
            
            sleep 10
          done
          
          # Final log retrieval
          echo "=== FINAL JOB OUTPUT ==="
          ~/.local/bin/kubectl logs -n ai -l job-name=${JOB_NAME} --tail=200
